{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":6993291,"sourceType":"datasetVersion","datasetId":4019558}],"dockerImageVersionId":30579,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nimport matplotlib.pyplot as plt\nimport time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ndata = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv', index_col='id')\nfeatures = ['prompt', 'A', 'B', 'C', 'D', 'E']\ny = data['answer']\nX = data[features]\n\ntrain_dataset = Dataset.from_pandas(data)\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-18T04:51:25.996249Z","iopub.execute_input":"2023-11-18T04:51:25.996691Z","iopub.status.idle":"2023-11-18T04:51:29.571357Z","shell.execute_reply.started":"2023-11-18T04:51:25.996652Z","shell.execute_reply":"2023-11-18T04:51:29.569976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n# comment the line below if you are finetuning RoBERTa\nmodel_dir = '/kaggle/input/finetuned-roberta/finetuned_roberta/checkpoint-750' \n# comment the line below if you are using a finetuned RoBERTa\n# model_dir = 'roberta-base'\ntokenizer = AutoTokenizer.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:51:46.046986Z","iopub.execute_input":"2023-11-18T04:51:46.047599Z","iopub.status.idle":"2023-11-18T04:51:51.801704Z","shell.execute_reply.started":"2023-11-18T04:51:46.047550Z","shell.execute_reply":"2023-11-18T04:51:51.800311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options = 'ABCDE'\nindices = list(range(5))\n\noption_index = {option: index for option, index in zip(options, indices)}\nindex_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(examples):\n    first_sentences = [examples['prompt']] * 5\n    second_sentences = []\n    for option in options:\n        second_sentences.append(examples[option])\n    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n    tokenized_examples['label'] = option_index[examples['answer']]\n    return tokenized_examples\n\ntokenized_train_ds = train_dataset.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:51:54.923270Z","iopub.execute_input":"2023-11-18T04:51:54.923927Z","iopub.status.idle":"2023-11-18T04:51:55.306410Z","shell.execute_reply.started":"2023-11-18T04:51:54.923889Z","shell.execute_reply":"2023-11-18T04:51:55.305055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Following datacollator (adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice)\n# will dynamically pad our questions at batch-time so we don't have to make every question the length\n# of our longest question.\nfrom dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:51:59.677821Z","iopub.execute_input":"2023-11-18T04:51:59.678260Z","iopub.status.idle":"2023-11-18T04:51:59.692259Z","shell.execute_reply.started":"2023-11-18T04:51:59.678224Z","shell.execute_reply":"2023-11-18T04:51:59.691120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:52:02.857486Z","iopub.execute_input":"2023-11-18T04:52:02.858126Z","iopub.status.idle":"2023-11-18T04:52:21.170195Z","shell.execute_reply.started":"2023-11-18T04:52:02.858089Z","shell.execute_reply":"2023-11-18T04:52:21.168438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(p):\n    # p.predictions are the predictions, p.label_ids are the true labels\n    preds = p.predictions.argmax(-1)\n    \n    accuracy = accuracy_score(p.label_ids, preds)\n    f1 = f1_score(p.label_ids, preds, average='weighted')  # Use 'binary' for binary classification\n    return {\n        'accuracy': accuracy,\n        'f1': f1\n    }","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:52:47.561382Z","iopub.execute_input":"2023-11-18T04:52:47.562261Z","iopub.status.idle":"2023-11-18T04:52:47.569577Z","shell.execute_reply.started":"2023-11-18T04:52:47.562219Z","shell.execute_reply":"2023-11-18T04:52:47.568279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainerCallback\n\n# this class allows us to save the path to the best performing model\nclass BestModelTracker(TrainerCallback):\n    def __init__(self):\n        self.best_loss = float('inf')\n        self.best_epoch = 0\n        self.best_model_path = None\n\n    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n        # Check if the current eval loss is lower than the best loss\n        if metrics and metrics.get(\"eval_loss\", float('inf')) < self.best_loss:\n            self.best_loss = metrics[\"eval_loss\"]\n            self.best_epoch = state.epoch\n            self.best_model_path = f'{args.output_dir}/checkpoint-{state.global_step}'\n            print(f\"New best model found at epoch {self.best_epoch} with eval loss: {self.best_loss}\")\n\nbest_model_tracker = BestModelTracker()\n\nmodel_dir = 'finetuned_roberta'\ntraining_args = TrainingArguments(\n        output_dir=f'{model_dir}',\n        evaluation_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        metric_for_best_model='eval_loss',  # Choose the metric to determine the best model\n        greater_is_better=False,  # Set to True if higher metric score is better\n        load_best_model_at_end=True,\n        learning_rate=5e-5,\n        per_device_train_batch_size=4,\n        per_device_eval_batch_size=4,\n        num_train_epochs=15,\n        weight_decay=0.01,\n        report_to='none',\n        save_total_limit=1\n    )\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_train_ds,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n    callbacks=[best_model_tracker]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:52:50.973154Z","iopub.execute_input":"2023-11-18T04:52:50.974334Z","iopub.status.idle":"2023-11-18T04:52:51.015381Z","shell.execute_reply.started":"2023-11-18T04:52:50.974284Z","shell.execute_reply":"2023-11-18T04:52:51.013117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uncomment if your notebook has access to Internet and you want to measure CPU/GPU usage\n\n# !pip install psutil GPUtil","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:30:50.172704Z","iopub.execute_input":"2023-11-18T04:30:50.173078Z","iopub.status.idle":"2023-11-18T04:31:01.677756Z","shell.execute_reply.started":"2023-11-18T04:30:50.173048Z","shell.execute_reply":"2023-11-18T04:31:01.676602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uncomment if your notebook has access to Internet and you want to measure CPU/GPU usage\n\n# import threading\n# import psutil\n# import GPUtil\n# import time\n\n# # Function to monitor CPU and GPU usage\n# def monitor_resources(stop_event, interval=1):\n#     cpu_usage = []\n#     gpu_usage = []\n#     timestamps = []\n\n#     while not stop_event.is_set():\n#         timestamps.append(time.time())\n#         cpu_usage.append(psutil.cpu_percent(interval=None))\n\n#         gpus = GPUtil.getGPUs()\n#         gpu_usage.append(gpus[0].load * 100 if gpus else 0)  # Assumes one GPU\n\n#         time.sleep(interval)\n\n#     plt.figure(figsize=(10, 6))\n#     plt.plot(timestamps, cpu_usage, label='CPU Usage (%)')\n#     plt.plot(timestamps, gpu_usage, label='GPU Usage (%)')\n#     plt.xlabel('Time (s)')\n#     plt.ylabel('Usage (%)')\n#     plt.title('CPU and GPU Usage Over Time')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.show()\n    \n#     print(timestamps)\n#     print(cpu_usage)\n#     print(gpu_usage)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:53:03.557661Z","iopub.execute_input":"2023-11-18T04:53:03.558111Z","iopub.status.idle":"2023-11-18T04:53:03.564115Z","shell.execute_reply.started":"2023-11-18T04:53:03.558057Z","shell.execute_reply":"2023-11-18T04:53:03.563048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all lines except trainer.train() are for measuring CPU/GPU usage\n\n# print(f'Start training')\n# # Monitoring setup\n# stop_event = threading.Event()\n# monitor_thread = threading.Thread(target=monitor_resources, args=(stop_event,))\n\n# # Start monitoring\n# monitor_thread.start()\n\n# # Train the model - uncomment if you want to finetune the model\n# trainer.train()\n\n# # Stop monitoring\n# stop_event.set()\n# monitor_thread.join()\n\n# print(f'Stopped training')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:36:56.523130Z","iopub.execute_input":"2023-11-18T04:36:56.523479Z","iopub.status.idle":"2023-11-18T04:40:36.359470Z","shell.execute_reply.started":"2023-11-18T04:36:56.523452Z","shell.execute_reply":"2023-11-18T04:40:36.358455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the best model\n\n# model = AutoModelForMultipleChoice.from_pretrained(best_model_tracker.best_model_path)\n# training_args = TrainingArguments(\n#         output_dir=f'{model_dir}',\n#         evaluation_strategy=\"epoch\",\n#         logging_strategy=\"epoch\",\n#         save_strategy=\"epoch\",\n#         metric_for_best_model='eval_loss',  # Choose the metric to determine the best model\n#         greater_is_better=False,  # Set to True if higher metric score is better\n#         load_best_model_at_end=True,\n#         learning_rate=5e-5,\n#         per_device_train_batch_size=4,\n#         per_device_eval_batch_size=4,\n#         num_train_epochs=15,\n#         weight_decay=0.01,\n#         report_to='none',\n#         save_total_limit=1\n#     )\n\n#     # Initialize the Trainer\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=tokenized_train_ds,\n#     eval_dataset=tokenized_train_ds,\n#     tokenizer=tokenizer,\n#     data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n#     compute_metrics=compute_metrics,\n# )","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:41:34.379752Z","iopub.execute_input":"2023-11-18T04:41:34.380493Z","iopub.status.idle":"2023-11-18T04:41:35.598731Z","shell.execute_reply.started":"2023-11-18T04:41:34.380458Z","shell.execute_reply":"2023-11-18T04:41:35.597694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#uncomment if you want to make predictions on the training set and measure CPU/GPU usage\n\n# # Monitoring setup\n# stop_event = threading.Event()\n# monitor_thread = threading.Thread(target=monitor_resources, args=(stop_event,))\n\n# # Start monitoring\n# monitor_thread.start()\n\n# # Start training\n# predictions = trainer.predict(tokenized_train_ds)\n\n# # Stop monitoring\n# stop_event.set()\n# monitor_thread.join()\n\n# # At this point, the monitoring thread has completed\n# print(\"Prediction inference and monitoring completed.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:41:40.338578Z","iopub.execute_input":"2023-11-18T04:41:40.339567Z","iopub.status.idle":"2023-11-18T04:41:43.654229Z","shell.execute_reply.started":"2023-11-18T04:41:40.339529Z","shell.execute_reply":"2023-11-18T04:41:43.653278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to generate three letter options\n\nimport numpy as np\ndef predictions_to_map_output(predictions):\n    sorted_answer_indices = np.argsort(-predictions)\n    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n    top_answers = np.vectorize(index_option.get)(top_answer_indices)\n    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:53:24.996387Z","iopub.execute_input":"2023-11-18T04:53:24.996808Z","iopub.status.idle":"2023-11-18T04:53:25.003939Z","shell.execute_reply.started":"2023-11-18T04:53:24.996773Z","shell.execute_reply":"2023-11-18T04:53:25.002696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#estimate MAP@3\n\ndef map_at_3(predictions, true_answers):\n    # Convert predictions to top 3 answers\n    top_3_predictions = predictions_to_map_output(predictions.predictions)\n\n    # Calculate average precision for each instance\n    average_precisions = []\n    for i in range(len(true_answers)):\n        true_answer = true_answers[i]\n        true_answer = options[true_answer]\n        predicted_answers = top_3_predictions[i].split(\" \")\n\n        if true_answer in predicted_answers:\n            index_of_true_answer = predicted_answers.index(true_answer)\n            precision_at_index = 1 / (index_of_true_answer + 1)\n            average_precisions.append(precision_at_index)\n        else:\n            average_precisions.append(0)\n\n    # Calculate mean average precision at 3\n    map_3 = np.mean(average_precisions)\n    return map_3","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:53:28.365319Z","iopub.execute_input":"2023-11-18T04:53:28.365742Z","iopub.status.idle":"2023-11-18T04:53:28.373744Z","shell.execute_reply.started":"2023-11-18T04:53:28.365708Z","shell.execute_reply":"2023-11-18T04:53:28.372698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#uncomment if you want to get MAP@3 score for the training set\n# true_answers = tokenized_train_ds['label']\n# print(f'MAP@3: {map_at_3(predictions, true_answers)}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:42:11.424891Z","iopub.execute_input":"2023-11-18T04:42:11.425845Z","iopub.status.idle":"2023-11-18T04:42:11.432991Z","shell.execute_reply.started":"2023-11-18T04:42:11.425807Z","shell.execute_reply":"2023-11-18T04:42:11.432027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:53:32.864139Z","iopub.execute_input":"2023-11-18T04:53:32.864576Z","iopub.status.idle":"2023-11-18T04:53:32.884682Z","shell.execute_reply.started":"2023-11-18T04:53:32.864541Z","shell.execute_reply":"2023-11-18T04:53:32.883186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['answer'] = 'A'\n\n# Other than that we'll preprocess it in the same way we preprocessed test.csv\ntest_ds = Dataset.from_pandas(test_df)\ntokenized_test_ds = test_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:53:36.288110Z","iopub.execute_input":"2023-11-18T04:53:36.289166Z","iopub.status.idle":"2023-11-18T04:53:36.581806Z","shell.execute_reply.started":"2023-11-18T04:53:36.289120Z","shell.execute_reply":"2023-11-18T04:53:36.580754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uncomment this if you want to measure CPU/GPU usage of making predictions on the test set\n# stop_event = threading.Event()\n# monitor_thread = threading.Thread(target=monitor_resources, args=(stop_event,))\n\n# # Start monitoring\n# monitor_thread.start()\n\n# # Start training\n# test_predictions = trainer.predict(tokenized_test_ds)\n# # Stop monitoring\n# stop_event.set()\n# monitor_thread.join()\n\n# # At this point, the monitoring thread has completed\n# print(\"Test prediction inference and monitoring completed.\")\n\n# run only this to make predicitons on the test set\ntest_predictions = trainer.predict(tokenized_test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:53:45.650291Z","iopub.execute_input":"2023-11-18T04:53:45.650742Z","iopub.status.idle":"2023-11-18T04:55:53.100443Z","shell.execute_reply.started":"2023-11-18T04:53:45.650704Z","shell.execute_reply":"2023-11-18T04:55:53.099368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a submission file\nsubmission_df = test_df[['id']]\nsubmission_df['prediction'] = predictions_to_map_output(test_predictions.predictions)\n\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:56:12.521943Z","iopub.execute_input":"2023-11-18T04:56:12.522438Z","iopub.status.idle":"2023-11-18T04:56:12.547632Z","shell.execute_reply.started":"2023-11-18T04:56:12.522399Z","shell.execute_reply":"2023-11-18T04:56:12.545832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-18T04:56:15.264089Z","iopub.execute_input":"2023-11-18T04:56:15.265225Z","iopub.status.idle":"2023-11-18T04:56:15.273909Z","shell.execute_reply.started":"2023-11-18T04:56:15.265175Z","shell.execute_reply":"2023-11-18T04:56:15.272647Z"},"trusted":true},"execution_count":null,"outputs":[]}]}