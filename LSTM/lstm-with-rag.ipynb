{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8792556a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:23:35.421343Z",
     "iopub.status.busy": "2023-11-25T09:23:35.420990Z",
     "iopub.status.idle": "2023-11-25T09:24:45.715795Z",
     "shell.execute_reply": "2023-11-25T09:24:45.714837Z"
    },
    "papermill": {
     "duration": 70.309377,
     "end_time": "2023-11-25T09:24:45.718088",
     "exception": false,
     "start_time": "2023-11-25T09:23:35.408711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Installing collected packages: faiss-gpu\r\n",
      "Successfully installed faiss-gpu-1.7.2\r\n",
      "Processing /kaggle/input/datasets-214/datasets-2.14.5-py3-none-any.whl\r\n",
      "Installing collected packages: datasets\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.1.0\r\n",
      "    Uninstalling datasets-2.1.0:\r\n",
      "      Successfully uninstalled datasets-2.1.0\r\n",
      "Successfully installed datasets-2.14.5\r\n",
      "Processing /kaggle/input/optimum-113/optimum-1.13.2-py3-none-any.whl\r\n",
      "Installing collected packages: optimum\r\n",
      "Successfully installed optimum-1.13.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --no-deps /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -U --no-deps /kaggle/input/datasets-214/datasets-2.14.5-py3-none-any.whl\n",
    "!pip install -U --no-deps /kaggle/input/optimum-113/optimum-1.13.2-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ef663ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-25T09:24:45.742472Z",
     "iopub.status.busy": "2023-11-25T09:24:45.741915Z",
     "iopub.status.idle": "2023-11-25T09:24:46.591639Z",
     "shell.execute_reply": "2023-11-25T09:24:46.590610Z"
    },
    "papermill": {
     "duration": 0.864929,
     "end_time": "2023-11-25T09:24:46.594362",
     "exception": false,
     "start_time": "2023-11-25T09:24:45.729433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bert/tensorflow2/bert-en-uncased-l-12-h-768-a-12/2/saved_model.pb\n",
      "/kaggle/input/bert/tensorflow2/bert-en-uncased-l-12-h-768-a-12/2/keras_metadata.pb\n",
      "/kaggle/input/bert/tensorflow2/bert-en-uncased-l-12-h-768-a-12/2/assets/vocab.txt\n",
      "/kaggle/input/bert/tensorflow2/bert-en-uncased-l-12-h-768-a-12/2/variables/variables.index\n",
      "/kaggle/input/bert/tensorflow2/bert-en-uncased-l-12-h-768-a-12/2/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/bert/tensorflow2/en-uncased-preprocess/3/saved_model.pb\n",
      "/kaggle/input/bert/tensorflow2/en-uncased-preprocess/3/keras_metadata.pb\n",
      "/kaggle/input/bert/tensorflow2/en-uncased-preprocess/3/assets/vocab.txt\n",
      "/kaggle/input/bert/tensorflow2/en-uncased-preprocess/3/variables/variables.index\n",
      "/kaggle/input/bert/tensorflow2/en-uncased-preprocess/3/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv\n",
      "/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv\n",
      "/kaggle/input/sci-or-not-sci-hypthesis-testing-pack/6000_wiki_en_sci_questions_with_excerpts.csv\n",
      "/kaggle/input/sci-or-not-sci-hypthesis-testing-pack/6000_all_categories_questions.csv\n",
      "/kaggle/input/sci-or-not-sci-hypthesis-testing-pack/6000_all_categories_questions_with_excerpts.csv\n",
      "/kaggle/input/sci-or-not-sci-hypthesis-testing-pack/6000_wiki_en_sci_questions.csv\n",
      "/kaggle/input/optimum-113/optimum-1.13.2-py3-none-any.whl\n",
      "/kaggle/input/all-paraphs-parsed-expanded/data-00002-of-00004.arrow\n",
      "/kaggle/input/all-paraphs-parsed-expanded/state.json\n",
      "/kaggle/input/all-paraphs-parsed-expanded/data-00003-of-00004.arrow\n",
      "/kaggle/input/all-paraphs-parsed-expanded/dataset_info.json\n",
      "/kaggle/input/all-paraphs-parsed-expanded/data-00000-of-00004.arrow\n",
      "/kaggle/input/all-paraphs-parsed-expanded/data-00001-of-00004.arrow\n",
      "/kaggle/input/datasets-214/datasets-2.14.5-py3-none-any.whl\n",
      "/kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/wikipedia-20230701/x.parquet\n",
      "/kaggle/input/wikipedia-20230701/h.parquet\n",
      "/kaggle/input/wikipedia-20230701/w.parquet\n",
      "/kaggle/input/wikipedia-20230701/g.parquet\n",
      "/kaggle/input/wikipedia-20230701/a.parquet\n",
      "/kaggle/input/wikipedia-20230701/y.parquet\n",
      "/kaggle/input/wikipedia-20230701/l.parquet\n",
      "/kaggle/input/wikipedia-20230701/n.parquet\n",
      "/kaggle/input/wikipedia-20230701/i.parquet\n",
      "/kaggle/input/wikipedia-20230701/number.parquet\n",
      "/kaggle/input/wikipedia-20230701/j.parquet\n",
      "/kaggle/input/wikipedia-20230701/m.parquet\n",
      "/kaggle/input/wikipedia-20230701/b.parquet\n",
      "/kaggle/input/wikipedia-20230701/r.parquet\n",
      "/kaggle/input/wikipedia-20230701/v.parquet\n",
      "/kaggle/input/wikipedia-20230701/z.parquet\n",
      "/kaggle/input/wikipedia-20230701/o.parquet\n",
      "/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\n",
      "/kaggle/input/wikipedia-20230701/k.parquet\n",
      "/kaggle/input/wikipedia-20230701/q.parquet\n",
      "/kaggle/input/wikipedia-20230701/e.parquet\n",
      "/kaggle/input/wikipedia-20230701/f.parquet\n",
      "/kaggle/input/wikipedia-20230701/p.parquet\n",
      "/kaggle/input/wikipedia-20230701/t.parquet\n",
      "/kaggle/input/wikipedia-20230701/other.parquet\n",
      "/kaggle/input/wikipedia-20230701/d.parquet\n",
      "/kaggle/input/wikipedia-20230701/u.parquet\n",
      "/kaggle/input/wikipedia-20230701/s.parquet\n",
      "/kaggle/input/wikipedia-20230701/c.parquet\n",
      "/kaggle/input/bge-small-faiss/config.json\n",
      "/kaggle/input/bge-small-faiss/faiss.index\n",
      "/kaggle/input/bge-small-faiss/tokenizer.json\n",
      "/kaggle/input/bge-small-faiss/tokenizer_config.json\n",
      "/kaggle/input/bge-small-faiss/pytorch_model.bin\n",
      "/kaggle/input/bge-small-faiss/special_tokens_map.json\n",
      "/kaggle/input/bge-small-faiss/vocab.txt\n",
      "/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\n",
      "/kaggle/input/kaggle-llm-science-exam/train.csv\n",
      "/kaggle/input/kaggle-llm-science-exam/test.csv\n",
      "/kaggle/input/15k-high-quality-examples/5900_examples.csv\n",
      "/kaggle/input/15k-high-quality-examples/15k_gpt3.5-turbo.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b133339",
   "metadata": {
    "papermill": {
     "duration": 0.011045,
     "end_time": "2023-11-25T09:24:46.617042",
     "exception": false,
     "start_time": "2023-11-25T09:24:46.605997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**SETTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c6ea38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:24:46.641096Z",
     "iopub.status.busy": "2023-11-25T09:24:46.640348Z",
     "iopub.status.idle": "2023-11-25T09:24:46.650856Z",
     "shell.execute_reply": "2023-11-25T09:24:46.649892Z"
    },
    "papermill": {
     "duration": 0.024722,
     "end_time": "2023-11-25T09:24:46.652851",
     "exception": false,
     "start_time": "2023-11-25T09:24:46.628129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentenceTransformer:\n",
    "    def __init__(self, checkpoint, device=\"cuda:1\"):\n",
    "        self.device = device\n",
    "        self.checkpoint = checkpoint\n",
    "        self.model = AutoModel.from_pretrained(checkpoint).to(self.device).half()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    def transform(self, batch):\n",
    "        tokens = self.tokenizer(batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\", max_length=MAX_SEQ_LEN)\n",
    "        return tokens.to(self.device)  \n",
    "\n",
    "    def get_dataloader(self, sentences, batch_size=32):\n",
    "        sentences = [\"Represent this sentence for searching relevant passages: \" + x for x in sentences]\n",
    "        dataset = Dataset.from_dict({\"text\": sentences})\n",
    "        dataset.set_transform(self.transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        return dataloader\n",
    "\n",
    "    def encode(self, sentences, show_progress_bar=False, batch_size=1):\n",
    "        dataloader = self.get_dataloader(sentences, batch_size=batch_size)\n",
    "        pbar = tqdm(dataloader) if show_progress_bar else dataloader\n",
    "\n",
    "        embeddings = []\n",
    "        for batch in pbar:\n",
    "            with torch.no_grad():\n",
    "                e = self.model(**batch).pooler_output\n",
    "                e = F.normalize(e, p=2, dim=1)\n",
    "                embeddings.append(e.detach().cpu().numpy())\n",
    "        embeddings = np.concatenate(embeddings, axis=0)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44668378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:24:46.677284Z",
     "iopub.status.busy": "2023-11-25T09:24:46.677016Z",
     "iopub.status.idle": "2023-11-25T09:24:53.302327Z",
     "shell.execute_reply": "2023-11-25T09:24:53.301334Z"
    },
    "papermill": {
     "duration": 6.640868,
     "end_time": "2023-11-25T09:24:53.304702",
     "exception": false,
     "start_time": "2023-11-25T09:24:46.663834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "MODEL_PATH = \"/kaggle/input/bge-small-faiss/\"\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "import gc\n",
    "# For RAG\n",
    "import faiss\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk, Dataset\n",
    "MAX_SEQ_LEN = 512\n",
    "import torch\n",
    "import ctypes\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "NUM_TITLES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b987fc52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:24:53.329960Z",
     "iopub.status.busy": "2023-11-25T09:24:53.329065Z",
     "iopub.status.idle": "2023-11-25T09:25:05.805491Z",
     "shell.execute_reply": "2023-11-25T09:25:05.804670Z"
    },
    "papermill": {
     "duration": 12.491248,
     "end_time": "2023-11-25T09:25:05.807922",
     "exception": false,
     "start_time": "2023-11-25T09:24:53.316674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7efafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:05.833315Z",
     "iopub.status.busy": "2023-11-25T09:25:05.832754Z",
     "iopub.status.idle": "2023-11-25T09:25:05.837625Z",
     "shell.execute_reply": "2023-11-25T09:25:05.836664Z"
    },
    "papermill": {
     "duration": 0.019478,
     "end_time": "2023-11-25T09:25:05.839746",
     "exception": false,
     "start_time": "2023-11-25T09:25:05.820268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_DICT = {\"A\":0,'B':1,'C':2,'D':3,'E':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73533d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:05.864959Z",
     "iopub.status.busy": "2023-11-25T09:25:05.864248Z",
     "iopub.status.idle": "2023-11-25T09:25:05.878871Z",
     "shell.execute_reply": "2023-11-25T09:25:05.877962Z"
    },
    "papermill": {
     "duration": 0.029151,
     "end_time": "2023-11-25T09:25:05.880786",
     "exception": false,
     "start_time": "2023-11-25T09:25:05.851635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(df,check_test= False):\n",
    "    X_Prompt = tf.convert_to_tensor(df.prompt.to_list()) \n",
    "    X_Context = tf.convert_to_tensor(df.context.to_list()) \n",
    "#     X_Context = tf.convert_to_tensor(df.context.apply(lambda x: x[:10]).to_list()) \n",
    "    X_A = tf.convert_to_tensor(df.A.astype(str).to_list())\n",
    "    X_B = tf.convert_to_tensor(df.B.astype(str).to_list())\n",
    "    X_C = tf.convert_to_tensor(df.C.astype(str).to_list())\n",
    "    X_D = tf.convert_to_tensor(df.D.astype(str).to_list())\n",
    "    X_E = tf.convert_to_tensor(df.E.astype(str).to_list())  \n",
    "    \n",
    "    Selects = {'A':X_A,\"B\":X_B,\"C\":X_C,'D':X_D,'E':X_E}\n",
    "    \n",
    "    Labels = labels_one_hot = None\n",
    "    \n",
    "    \n",
    "    if not check_test:\n",
    "        labels = df.answer.to_list()\n",
    "        labels_one_hot = [LABEL_DICT.get(i) for i in labels]\n",
    "\n",
    "        label_A = []\n",
    "        label_B = []\n",
    "        label_C = []\n",
    "        label_D = []\n",
    "        label_E = []\n",
    "\n",
    "        for i in labels:\n",
    "            if i =='A':\n",
    "                label_A.append(0.8)\n",
    "                label_B.append(0.05)\n",
    "                label_C.append(0.05)\n",
    "                label_D.append(0.05)  \n",
    "                label_E.append(0.05)\n",
    "            if i =='B':\n",
    "                label_B.append(0.8)\n",
    "                label_A.append(0.05)\n",
    "                label_C.append(0.05)\n",
    "                label_D.append(0.05)  \n",
    "                label_E.append(0.05)\n",
    "\n",
    "            if i =='C':\n",
    "                label_C.append(0.8)\n",
    "                label_A.append(0.05)\n",
    "                label_B.append(0.05)\n",
    "                label_D.append(0.05)  \n",
    "                label_E.append(0.05)\n",
    "            if i =='D':\n",
    "                label_D.append(0.8)\n",
    "                label_A.append(0.05)\n",
    "                label_B.append(0.05)\n",
    "                label_C.append(0.05) \n",
    "                label_E.append(0.05)\n",
    "            if i =='E':\n",
    "                label_E.append(0.8)\n",
    "                label_A.append(0.05)\n",
    "                label_B.append(0.05)\n",
    "                label_C.append(0.05)\n",
    "                label_D.append(0.05)  \n",
    "        label_A = tf.convert_to_tensor(label_A)\n",
    "        label_B = tf.convert_to_tensor(label_B)\n",
    "        label_C = tf.convert_to_tensor(label_C)\n",
    "        label_D = tf.convert_to_tensor(label_D)\n",
    "        label_E = tf.convert_to_tensor(label_E)\n",
    "\n",
    "\n",
    "        Labels  = {'A': label_A,'B': label_B,'C': label_C,'D': label_D,'E': label_E}\n",
    "    return {'Prompt':X_Prompt,'Context': X_Context,'Selects':Selects,'labels':Labels,'label_onehot':labels_one_hot}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f0196",
   "metadata": {
    "papermill": {
     "duration": 0.010879,
     "end_time": "2023-11-25T09:25:05.903280",
     "exception": false,
     "start_time": "2023-11-25T09:25:05.892401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**INPUT TRAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd38a22",
   "metadata": {
    "papermill": {
     "duration": 0.011558,
     "end_time": "2023-11-25T09:25:05.926561",
     "exception": false,
     "start_time": "2023-11-25T09:25:05.915003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*4 thread model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2227fe0",
   "metadata": {
    "papermill": {
     "duration": 0.011298,
     "end_time": "2023-11-25T09:25:05.949613",
     "exception": false,
     "start_time": "2023-11-25T09:25:05.938315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Binary model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d08444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:05.975850Z",
     "iopub.status.busy": "2023-11-25T09:25:05.975421Z",
     "iopub.status.idle": "2023-11-25T09:25:13.802329Z",
     "shell.execute_reply": "2023-11-25T09:25:13.801186Z"
    },
    "papermill": {
     "duration": 7.843427,
     "end_time": "2023-11-25T09:25:13.804843",
     "exception": false,
     "start_time": "2023-11-25T09:25:05.961416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_faiss = SentenceTransformer(MODEL_PATH, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a192a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:13.829801Z",
     "iopub.status.busy": "2023-11-25T09:25:13.829422Z",
     "iopub.status.idle": "2023-11-25T09:25:13.940251Z",
     "shell.execute_reply": "2023-11-25T09:25:13.939466Z"
    },
    "papermill": {
     "duration": 0.126082,
     "end_time": "2023-11-25T09:25:13.943030",
     "exception": false,
     "start_time": "2023-11-25T09:25:13.816948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = ['/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv', '/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv']\n",
    "df = pd.read_csv(path[0])\n",
    "lst = ['prompt','A','B','C','D','E','answer']\n",
    "df = df[lst]\n",
    "for i in path[1:]:\n",
    "    newdf = pd.read_csv(i)[lst]\n",
    "    df = pd.concat([df,newdf])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce0a2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:13.969196Z",
     "iopub.status.busy": "2023-11-25T09:25:13.968868Z",
     "iopub.status.idle": "2023-11-25T09:25:13.981436Z",
     "shell.execute_reply": "2023-11-25T09:25:13.980494Z"
    },
    "papermill": {
     "duration": 0.027129,
     "end_time": "2023-11-25T09:25:13.983531",
     "exception": false,
     "start_time": "2023-11-25T09:25:13.956402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv').drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91552f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:14.009324Z",
     "iopub.status.busy": "2023-11-25T09:25:14.009005Z",
     "iopub.status.idle": "2023-11-25T09:25:14.029266Z",
     "shell.execute_reply": "2023-11-25T09:25:14.028354Z"
    },
    "papermill": {
     "duration": 0.035202,
     "end_time": "2023-11-25T09:25:14.031178",
     "exception": false,
     "start_time": "2023-11-25T09:25:13.995976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In relation to Eunice Fay McKenzie's career, w...</td>\n",
       "      <td>McKenzie showcased her singing talents in nume...</td>\n",
       "      <td>McKenzie is primarily remembered for her starr...</td>\n",
       "      <td>McKenzie gained recognition for her role as a ...</td>\n",
       "      <td>McKenzie's collaborations with director Blake ...</td>\n",
       "      <td>McKenzie's successful career in sound films co...</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Modified Newtonian Dynamics (MOND) im...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND explains the missing baryonic mass in gal...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>MOND's impact on the observed missing baryonic...</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of the Museum of the ...</td>\n",
       "      <td>The Museum of the Occupation of Latvia is a me...</td>\n",
       "      <td>The Museum of the Occupation of Latvia showcas...</td>\n",
       "      <td>The Museum of the Occupation of Latvia was est...</td>\n",
       "      <td>The Museum of the Occupation of Latvia primari...</td>\n",
       "      <td>The Museum of the Occupation of Latvia is a mu...</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the previous name of the Christian Sc...</td>\n",
       "      <td>The Christian School for the Deaf (CSD)</td>\n",
       "      <td>The Christian School for the Blind (CSB)</td>\n",
       "      <td>The Evangelical School and Chapel for the Deaf...</td>\n",
       "      <td>The Evangelical School for the Deaf (ESD)</td>\n",
       "      <td>The Evangelical School for the Blind (ESB)</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  In relation to Eunice Fay McKenzie's career, w...   \n",
       "1  How does Modified Newtonian Dynamics (MOND) im...   \n",
       "2  Which of the following statements accurately d...   \n",
       "3  What is the significance of the Museum of the ...   \n",
       "4  What was the previous name of the Christian Sc...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  McKenzie showcased her singing talents in nume...   \n",
       "1  MOND is a theory that increases the discrepanc...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia is a me...   \n",
       "4            The Christian School for the Deaf (CSD)   \n",
       "\n",
       "                                                   B  \\\n",
       "0  McKenzie is primarily remembered for her starr...   \n",
       "1  MOND explains the missing baryonic mass in gal...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia showcas...   \n",
       "4           The Christian School for the Blind (CSB)   \n",
       "\n",
       "                                                   C  \\\n",
       "0  McKenzie gained recognition for her role as a ...   \n",
       "1  MOND is a theory that reduces the observed mis...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia was est...   \n",
       "4  The Evangelical School and Chapel for the Deaf...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  McKenzie's collaborations with director Blake ...   \n",
       "1  MOND is a theory that eliminates the observed ...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia primari...   \n",
       "4          The Evangelical School for the Deaf (ESD)   \n",
       "\n",
       "                                                   E answer  train  \n",
       "0  McKenzie's successful career in sound films co...      B   True  \n",
       "1  MOND's impact on the observed missing baryonic...      E   True  \n",
       "2  Ray Montgomerie is a former footballer who pla...      B   True  \n",
       "3  The Museum of the Occupation of Latvia is a mu...      C   True  \n",
       "4         The Evangelical School for the Blind (ESB)      D   True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['train'] = True\n",
    "df_test['train'] = False\n",
    "df = pd.concat([df,df_test]).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86260fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:25:14.055150Z",
     "iopub.status.busy": "2023-11-25T09:25:14.054855Z",
     "iopub.status.idle": "2023-11-25T09:28:31.702278Z",
     "shell.execute_reply": "2023-11-25T09:28:31.700970Z"
    },
    "papermill": {
     "duration": 197.66187,
     "end_time": "2023-11-25T09:28:31.704474",
     "exception": false,
     "start_time": "2023-11-25T09:25:14.042604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt embedding, t=0.0s\n",
      "Loading faiss index, t=94.0s\n",
      "Starting text search, t=122.0s\n",
      "Starting context extraction, t=173.7s\n",
      "Context added, t=197.6s\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "start = time()\n",
    "print(f\"Starting prompt embedding, t={time() - start :.1f}s\")\n",
    "\n",
    "# Get embeddings of prompts\n",
    "f = lambda row : \" \".join([str(row[\"prompt\"]), str(row[\"A\"]), str(row[\"B\"]), str(row[\"C\"]), str(row[\"D\"]), str(row[\"E\"])])\n",
    "inputs = df.apply(f, axis=1).values # better results than prompt only\n",
    "prompt_embeddings = model_faiss.encode(inputs, show_progress_bar=False)\n",
    "\n",
    "# Search closest sentences in the wikipedia index \n",
    "print(f\"Loading faiss index, t={time() - start :.1f}s\")\n",
    "faiss_index = faiss.read_index(MODEL_PATH + '/faiss.index')\n",
    "# faiss_index = faiss.index_cpu_to_all_gpus(faiss_index) # causes OOM, and not that long on CPU\n",
    "\n",
    "print(f\"Starting text search, t={time() - start :.1f}s\")\n",
    "search_index = faiss_index.search(np.float32(prompt_embeddings), NUM_TITLES)[1]\n",
    "\n",
    "print(f\"Starting context extraction, t={time() - start :.1f}s\")\n",
    "dataset = load_from_disk(\"/kaggle/input/all-paraphs-parsed-expanded\")\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, \"context\"] = \"-\" + \"\\n-\".join([dataset[int(j)][\"text\"] for j in search_index[i]])\n",
    "\n",
    "# Free memory\n",
    "faiss_index.reset()\n",
    "del faiss_index, prompt_embeddings, dataset\n",
    "clean_memory()\n",
    "print(f\"Context added, t={time() - start :.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721aa865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:31.731082Z",
     "iopub.status.busy": "2023-11-25T09:28:31.730765Z",
     "iopub.status.idle": "2023-11-25T09:28:32.200135Z",
     "shell.execute_reply": "2023-11-25T09:28:32.199109Z"
    },
    "papermill": {
     "duration": 0.485491,
     "end_time": "2023-11-25T09:28:32.202579",
     "exception": false,
     "start_time": "2023-11-25T09:28:31.717088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = read_data(df[df['train']],False)\n",
    "X_Prompt = result.get('Prompt') \n",
    "X_Context = result.get('Context') \n",
    "X_A = result.get('Selects').get('A')\n",
    "X_B = result.get('Selects').get('B')\n",
    "X_C = result.get('Selects').get('C')\n",
    "X_D = result.get('Selects').get('D')\n",
    "X_E = result.get('Selects').get('E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2451fbc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:32.228145Z",
     "iopub.status.busy": "2023-11-25T09:28:32.227829Z",
     "iopub.status.idle": "2023-11-25T09:28:32.245425Z",
     "shell.execute_reply": "2023-11-25T09:28:32.244428Z"
    },
    "papermill": {
     "duration": 0.03306,
     "end_time": "2023-11-25T09:28:32.247846",
     "exception": false,
     "start_time": "2023-11-25T09:28:32.214786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Selects = [result.get('Selects')[i] for i in result.get('Selects') ]\n",
    "Selects.insert(0,X_Context)\n",
    "Selects.insert(0,X_Prompt)\n",
    "labels = [result.get('labels')[i] for i in result.get('labels') ]\n",
    "labels_one_hot = result.get('label_onehot')\n",
    "labels_one_hot_train = tf.one_hot(labels_one_hot, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0450578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:32.276141Z",
     "iopub.status.busy": "2023-11-25T09:28:32.275838Z",
     "iopub.status.idle": "2023-11-25T09:28:32.292883Z",
     "shell.execute_reply": "2023-11-25T09:28:32.292019Z"
    },
    "papermill": {
     "duration": 0.033899,
     "end_time": "2023-11-25T09:28:32.295083",
     "exception": false,
     "start_time": "2023-11-25T09:28:32.261184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_val = read_data(df[~df['train']] ,False)\n",
    "X_Prompt_val  = result_val.get('Prompt') \n",
    "X_Context_val = result_val.get('Context') \n",
    "X_A_val  = result_val .get('Selects').get('A')\n",
    "X_B_val  = result_val .get('Selects').get('B')\n",
    "X_C_val  = result_val .get('Selects').get('C')\n",
    "X_D_val  = result_val .get('Selects').get('D')\n",
    "X_E_val  = result_val .get('Selects').get('E')\n",
    "\n",
    "Selects_val  = [result_val .get('Selects')[i] for i in result_val .get('Selects') ]\n",
    "Selects_val .insert(0,X_Context_val )\n",
    "Selects_val .insert(0,X_Prompt_val )\n",
    "labels_val  = [result_val .get('labels')[i] for i in result_val .get('labels') ]\n",
    "labels_one = result_val.get('label_onehot')\n",
    "labels_one_hot_val = tf.one_hot(labels_one, depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6719512",
   "metadata": {
    "papermill": {
     "duration": 0.011662,
     "end_time": "2023-11-25T09:28:32.320149",
     "exception": false,
     "start_time": "2023-11-25T09:28:32.308487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**LOAD MODEL BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f6300f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:32.345646Z",
     "iopub.status.busy": "2023-11-25T09:28:32.345252Z",
     "iopub.status.idle": "2023-11-25T09:28:47.997591Z",
     "shell.execute_reply": "2023-11-25T09:28:47.996777Z"
    },
    "papermill": {
     "duration": 15.667311,
     "end_time": "2023-11-25T09:28:47.999803",
     "exception": false,
     "start_time": "2023-11-25T09:28:32.332492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"/kaggle/input/bert/tensorflow2/en-uncased-preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"/kaggle/input/bert/tensorflow2/bert-en-uncased-l-12-h-768-a-12/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b96385",
   "metadata": {
    "papermill": {
     "duration": 0.012361,
     "end_time": "2023-11-25T09:28:48.024676",
     "exception": false,
     "start_time": "2023-11-25T09:28:48.012315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**BUILD MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8151453c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:48.049836Z",
     "iopub.status.busy": "2023-11-25T09:28:48.049476Z",
     "iopub.status.idle": "2023-11-25T09:28:48.728305Z",
     "shell.execute_reply": "2023-11-25T09:28:48.727479Z"
    },
    "papermill": {
     "duration": 0.694067,
     "end_time": "2023-11-25T09:28:48.730834",
     "exception": false,
     "start_time": "2023-11-25T09:28:48.036767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_Prompt = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "text_Context = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "text_A = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "text_B = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "text_C = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "text_D = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "text_E = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "\n",
    "encoder_prompt_input = bert_preprocess(text_Prompt)\n",
    "encoder_context_input = bert_preprocess(text_Context)\n",
    "encoder_A_input = bert_preprocess(text_A)\n",
    "encoder_B_input = bert_preprocess(text_B)\n",
    "encoder_C_input = bert_preprocess(text_C)\n",
    "encoder_D_input = bert_preprocess(text_D)\n",
    "encoder_E_input = bert_preprocess(text_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ef0be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:48.757202Z",
     "iopub.status.busy": "2023-11-25T09:28:48.756890Z",
     "iopub.status.idle": "2023-11-25T09:28:52.690400Z",
     "shell.execute_reply": "2023-11-25T09:28:52.689232Z"
    },
    "papermill": {
     "duration": 4.008334,
     "end_time": "2023-11-25T09:28:52.752040",
     "exception": false,
     "start_time": "2023-11-25T09:28:48.743706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3072)\n",
      "reshape:  (None, 4, 768)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)    {'input_word_ids': (None,    0         ['input_1[0][0]',             \n",
      "                             128),                                   'input_2[0][0]',             \n",
      "                              'input_type_ids': (None,               'input_3[0][0]',             \n",
      "                             128),                                   'input_4[0][0]',             \n",
      "                              'input_mask': (None, 128)              'input_5[0][0]',             \n",
      "                             }                                       'input_6[0][0]',             \n",
      "                                                                     'input_7[0][0]']             \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)  {'pooled_output': (None, 7   1094822   ['keras_layer[0][0]',         \n",
      "                             68),                         41         'keras_layer[0][1]',         \n",
      "                              'default': (None, 768),                'keras_layer[0][2]',         \n",
      "                              'encoder_outputs': [(None              'keras_layer[0][0]',         \n",
      "                             , 128, 768),                            'keras_layer[0][1]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][2]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][0]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][1]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][2]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][0]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][1]',         \n",
      "                              (None, 128, 768),                      'keras_layer[0][2]',         \n",
      "                              (None, 128, 768),                      'keras_layer[1][0]',         \n",
      "                              (None, 128, 768),                      'keras_layer[1][1]',         \n",
      "                              (None, 128, 768),                      'keras_layer[1][2]',         \n",
      "                              (None, 128, 768)],                     'keras_layer[1][0]',         \n",
      "                              'sequence_output': (None,              'keras_layer[1][1]',         \n",
      "                              128, 768)}                             'keras_layer[1][2]',         \n",
      "                                                                     'keras_layer[1][0]',         \n",
      "                                                                     'keras_layer[1][1]',         \n",
      "                                                                     'keras_layer[1][2]',         \n",
      "                                                                     'keras_layer[1][0]',         \n",
      "                                                                     'keras_layer[1][1]',         \n",
      "                                                                     'keras_layer[1][2]',         \n",
      "                                                                     'keras_layer[2][0]',         \n",
      "                                                                     'keras_layer[2][1]',         \n",
      "                                                                     'keras_layer[2][2]',         \n",
      "                                                                     'keras_layer[2][0]',         \n",
      "                                                                     'keras_layer[2][1]',         \n",
      "                                                                     'keras_layer[2][2]',         \n",
      "                                                                     'keras_layer[2][0]',         \n",
      "                                                                     'keras_layer[2][1]',         \n",
      "                                                                     'keras_layer[2][2]',         \n",
      "                                                                     'keras_layer[2][0]',         \n",
      "                                                                     'keras_layer[2][1]',         \n",
      "                                                                     'keras_layer[2][2]',         \n",
      "                                                                     'keras_layer[3][0]',         \n",
      "                                                                     'keras_layer[3][1]',         \n",
      "                                                                     'keras_layer[3][2]',         \n",
      "                                                                     'keras_layer[3][0]',         \n",
      "                                                                     'keras_layer[3][1]',         \n",
      "                                                                     'keras_layer[3][2]',         \n",
      "                                                                     'keras_layer[3][0]',         \n",
      "                                                                     'keras_layer[3][1]',         \n",
      "                                                                     'keras_layer[3][2]',         \n",
      "                                                                     'keras_layer[3][0]',         \n",
      "                                                                     'keras_layer[3][1]',         \n",
      "                                                                     'keras_layer[3][2]',         \n",
      "                                                                     'keras_layer[4][0]',         \n",
      "                                                                     'keras_layer[4][1]',         \n",
      "                                                                     'keras_layer[4][2]',         \n",
      "                                                                     'keras_layer[4][0]',         \n",
      "                                                                     'keras_layer[4][1]',         \n",
      "                                                                     'keras_layer[4][2]',         \n",
      "                                                                     'keras_layer[4][0]',         \n",
      "                                                                     'keras_layer[4][1]',         \n",
      "                                                                     'keras_layer[4][2]',         \n",
      "                                                                     'keras_layer[4][0]',         \n",
      "                                                                     'keras_layer[4][1]',         \n",
      "                                                                     'keras_layer[4][2]',         \n",
      "                                                                     'keras_layer[5][0]',         \n",
      "                                                                     'keras_layer[5][1]',         \n",
      "                                                                     'keras_layer[5][2]',         \n",
      "                                                                     'keras_layer[5][0]',         \n",
      "                                                                     'keras_layer[5][1]',         \n",
      "                                                                     'keras_layer[5][2]',         \n",
      "                                                                     'keras_layer[5][0]',         \n",
      "                                                                     'keras_layer[5][1]',         \n",
      "                                                                     'keras_layer[5][2]',         \n",
      "                                                                     'keras_layer[5][0]',         \n",
      "                                                                     'keras_layer[5][1]',         \n",
      "                                                                     'keras_layer[5][2]',         \n",
      "                                                                     'keras_layer[6][0]',         \n",
      "                                                                     'keras_layer[6][1]',         \n",
      "                                                                     'keras_layer[6][2]',         \n",
      "                                                                     'keras_layer[6][0]',         \n",
      "                                                                     'keras_layer[6][1]',         \n",
      "                                                                     'keras_layer[6][2]',         \n",
      "                                                                     'keras_layer[6][0]',         \n",
      "                                                                     'keras_layer[6][1]',         \n",
      "                                                                     'keras_layer[6][2]',         \n",
      "                                                                     'keras_layer[6][0]',         \n",
      "                                                                     'keras_layer[6][1]',         \n",
      "                                                                     'keras_layer[6][2]']         \n",
      "                                                                                                  \n",
      " hidden_states_prompt_1 (Co  (None, 128, 3072)            0         ['keras_layer_1[0][9]',       \n",
      " ncatenate)                                                          'keras_layer_1[1][10]',      \n",
      "                                                                     'keras_layer_1[2][11]',      \n",
      "                                                                     'keras_layer_1[3][12]']      \n",
      "                                                                                                  \n",
      " hidden_states_context_1 (C  (None, 128, 3072)            0         ['keras_layer_1[4][9]',       \n",
      " oncatenate)                                                         'keras_layer_1[5][10]',      \n",
      "                                                                     'keras_layer_1[6][11]',      \n",
      "                                                                     'keras_layer_1[7][12]']      \n",
      "                                                                                                  \n",
      " hidden_states_A (Concatena  (None, 128, 3072)            0         ['keras_layer_1[8][9]',       \n",
      " te)                                                                 'keras_layer_1[9][10]',      \n",
      "                                                                     'keras_layer_1[10][11]',     \n",
      "                                                                     'keras_layer_1[11][12]']     \n",
      "                                                                                                  \n",
      " hidden_states_B (Concatena  (None, 128, 3072)            0         ['keras_layer_1[12][9]',      \n",
      " te)                                                                 'keras_layer_1[13][10]',     \n",
      "                                                                     'keras_layer_1[14][11]',     \n",
      "                                                                     'keras_layer_1[15][12]']     \n",
      "                                                                                                  \n",
      " hidden_states_C (Concatena  (None, 128, 3072)            0         ['keras_layer_1[16][9]',      \n",
      " te)                                                                 'keras_layer_1[17][10]',     \n",
      "                                                                     'keras_layer_1[18][11]',     \n",
      "                                                                     'keras_layer_1[19][12]']     \n",
      "                                                                                                  \n",
      " hidden_states_D (Concatena  (None, 128, 3072)            0         ['keras_layer_1[20][9]',      \n",
      " te)                                                                 'keras_layer_1[21][10]',     \n",
      "                                                                     'keras_layer_1[22][11]',     \n",
      "                                                                     'keras_layer_1[23][12]']     \n",
      "                                                                                                  \n",
      " hidden_states_E (Concatena  (None, 128, 3072)            0         ['keras_layer_1[24][9]',      \n",
      " te)                                                                 'keras_layer_1[25][10]',     \n",
      "                                                                     'keras_layer_1[26][11]',     \n",
      "                                                                     'keras_layer_1[27][12]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 3072)                 0         ['hidden_states_prompt_1[0][0]\n",
      " SlicingOpLambda)                                                   ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 3072)                 0         ['hidden_states_context_1[0][0\n",
      "  (SlicingOpLambda)                                                 ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  (None, 3072)                 0         ['hidden_states_A[0][0]']     \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 3072)                 0         ['hidden_states_B[0][0]']     \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 3072)                 0         ['hidden_states_C[0][0]']     \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5  (None, 3072)                 0         ['hidden_states_D[0][0]']     \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 3072)                 0         ['hidden_states_E[0][0]']     \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (None, 4, 768)               0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)   (None, 4, 768)               0         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)   (None, 4, 768)               0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)   (None, 4, 768)               0         ['tf.__operators__.getitem_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_4 (TFOpLambda)   (None, 4, 768)               0         ['tf.__operators__.getitem_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_5 (TFOpLambda)   (None, 4, 768)               0         ['tf.__operators__.getitem_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.reshape_6 (TFOpLambda)   (None, 4, 768)               0         ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 768)              0         ['tf.reshape[0][0]',          \n",
      "                                                                     'tf.reshape_1[0][0]',        \n",
      "                                                                     'tf.reshape_2[0][0]',        \n",
      "                                                                     'tf.reshape_3[0][0]',        \n",
      "                                                                     'tf.reshape_4[0][0]',        \n",
      "                                                                     'tf.reshape_5[0][0]',        \n",
      "                                                                     'tf.reshape_6[0][0]']        \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 28, 32)               102528    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 28, 32)               1056      ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 28, 32)               0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 28, 32)               64        ['dropout[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 28, 32)               0         ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 896)                  0         ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 5)                    4485      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 5)                    30        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109590404 (418.05 MB)\n",
      "Trainable params: 108163 (422.51 KB)\n",
      "Non-trainable params: 109482241 (417.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_prompt = concatenate(\n",
    "        tuple([bert_encoder(encoder_prompt_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_prompt_1',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "encoder_context = concatenate(\n",
    "        tuple([bert_encoder(encoder_context_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_context_1',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "encoder_A = concatenate(\n",
    "        tuple([bert_encoder(encoder_A_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_A',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "encoder_B = concatenate(\n",
    "        tuple([bert_encoder(encoder_B_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_B',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "encoder_C = concatenate(\n",
    "        tuple([bert_encoder(encoder_C_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_C',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "encoder_D = concatenate(\n",
    "        tuple([bert_encoder(encoder_D_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_D',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "encoder_E = concatenate(\n",
    "        tuple([bert_encoder(encoder_E_input)['encoder_outputs'][i] for i in range(-4, 0)]), \n",
    "        name = 'hidden_states_E',\n",
    "        axis = -1\n",
    "    )[:, 0, :]\n",
    "print(encoder_E.shape)\n",
    "\n",
    "reshape_prompt = tf.reshape(encoder_prompt, (-1, 4, 768))\n",
    "reshape_context = tf.reshape(encoder_context, (-1, 4, 768))\n",
    "reshape_A = tf.reshape(encoder_A, (-1, 4, 768))\n",
    "reshape_B = tf.reshape(encoder_B, (-1, 4, 768))\n",
    "reshape_C = tf.reshape(encoder_C, (-1, 4, 768))\n",
    "reshape_D = tf.reshape(encoder_D, (-1, 4, 768))\n",
    "reshape_E = tf.reshape(encoder_E, (-1, 4, 768))\n",
    "print('reshape: ', reshape_A.shape)\n",
    "# layer A\n",
    "concat_encoder_A = concatenate([reshape_prompt,reshape_context, reshape_A,reshape_B,reshape_C,reshape_D,reshape_E],axis = 1)\n",
    "LSTM = tf.keras.layers.LSTM(units=32,dropout=0.2, recurrent_dropout=0.2,return_sequences=True)(concat_encoder_A)\n",
    "Dense_prompt_A = tf.keras.layers.Dense(32,activation = 'relu')(LSTM)\n",
    "Dense_prompt_A =  tf.keras.layers.Dropout(0.3)(Dense_prompt_A)\n",
    "Dense_prompt_A = tf.keras.layers.LayerNormalization()(Dense_prompt_A)\n",
    "Linear_A =  tf.keras.layers.Dropout(0.3)(Dense_prompt_A)\n",
    "classifer = keras.layers.Flatten()(Linear_A)\n",
    "classifer = tf.keras.layers.Dense(5,activation = 'linear')(classifer)\n",
    "classifer =  tf.keras.layers.Dense(5,activation = 'softmax')(classifer)\n",
    "\n",
    "model = keras.Model(inputs=[text_Prompt, text_Context, text_A,text_B,text_C,text_D,text_E], outputs=classifer)\n",
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1dea40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:52.813606Z",
     "iopub.status.busy": "2023-11-25T09:28:52.813278Z",
     "iopub.status.idle": "2023-11-25T09:28:52.818399Z",
     "shell.execute_reply": "2023-11-25T09:28:52.817209Z"
    },
    "papermill": {
     "duration": 0.038831,
     "end_time": "2023-11-25T09:28:52.820410",
     "exception": false,
     "start_time": "2023-11-25T09:28:52.781579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=10,\n",
    "                    restore_best_weights=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cb68bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:52.882647Z",
     "iopub.status.busy": "2023-11-25T09:28:52.882340Z",
     "iopub.status.idle": "2023-11-25T09:28:52.886230Z",
     "shell.execute_reply": "2023-11-25T09:28:52.885376Z"
    },
    "papermill": {
     "duration": 0.036093,
     "end_time": "2023-11-25T09:28:52.888165",
     "exception": false,
     "start_time": "2023-11-25T09:28:52.852072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a0d753a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T09:28:52.946865Z",
     "iopub.status.busy": "2023-11-25T09:28:52.946584Z",
     "iopub.status.idle": "2023-11-25T15:01:44.028406Z",
     "shell.execute_reply": "2023-11-25T15:01:44.027456Z"
    },
    "papermill": {
     "duration": 19971.355999,
     "end_time": "2023-11-25T15:01:44.272813",
     "exception": false,
     "start_time": "2023-11-25T09:28:52.916814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60/60 [==============================] - 560s 8s/step - loss: 2.1730 - accuracy: 0.1885 - val_loss: 1.6369 - val_accuracy: 0.2400\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.8596 - accuracy: 0.2135 - val_loss: 1.6509 - val_accuracy: 0.2350\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.7702 - accuracy: 0.2000 - val_loss: 1.6386 - val_accuracy: 0.1700\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 493s 8s/step - loss: 1.7065 - accuracy: 0.2019 - val_loss: 1.6147 - val_accuracy: 0.1950\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.6708 - accuracy: 0.2068 - val_loss: 1.6251 - val_accuracy: 0.2150\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.6565 - accuracy: 0.2104 - val_loss: 1.6229 - val_accuracy: 0.1850\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 492s 8s/step - loss: 1.6478 - accuracy: 0.2019 - val_loss: 1.6258 - val_accuracy: 0.1900\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.6360 - accuracy: 0.2161 - val_loss: 1.6057 - val_accuracy: 0.1900\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.6327 - accuracy: 0.2109 - val_loss: 1.6010 - val_accuracy: 0.2000\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.6306 - accuracy: 0.2026 - val_loss: 1.6007 - val_accuracy: 0.2550\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 493s 8s/step - loss: 1.6240 - accuracy: 0.2172 - val_loss: 1.6091 - val_accuracy: 0.2150\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.6340 - accuracy: 0.1964 - val_loss: 1.6636 - val_accuracy: 0.1650\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.6264 - accuracy: 0.2109 - val_loss: 1.6178 - val_accuracy: 0.1900\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 492s 8s/step - loss: 1.6019 - accuracy: 0.2505 - val_loss: 1.6345 - val_accuracy: 0.1850\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 501s 8s/step - loss: 1.6053 - accuracy: 0.2406 - val_loss: 1.5815 - val_accuracy: 0.2800\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.5995 - accuracy: 0.2516 - val_loss: 1.5754 - val_accuracy: 0.2900\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 494s 8s/step - loss: 1.5835 - accuracy: 0.2696 - val_loss: 1.5744 - val_accuracy: 0.2200\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.5541 - accuracy: 0.3026 - val_loss: 1.5476 - val_accuracy: 0.2650\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 501s 8s/step - loss: 1.5657 - accuracy: 0.2969 - val_loss: 1.5332 - val_accuracy: 0.2950\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.5657 - accuracy: 0.2880 - val_loss: 1.5408 - val_accuracy: 0.3250\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 493s 8s/step - loss: 1.5318 - accuracy: 0.3166 - val_loss: 1.5059 - val_accuracy: 0.3850\n",
      "Epoch 22/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.5133 - accuracy: 0.3469 - val_loss: 1.5076 - val_accuracy: 0.3400\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.5343 - accuracy: 0.3094 - val_loss: 1.5053 - val_accuracy: 0.3700\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 493s 8s/step - loss: 1.5037 - accuracy: 0.3330 - val_loss: 1.4755 - val_accuracy: 0.3550\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 498s 8s/step - loss: 1.4696 - accuracy: 0.3714 - val_loss: 1.4812 - val_accuracy: 0.3850\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.4712 - accuracy: 0.3651 - val_loss: 1.4331 - val_accuracy: 0.3850\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 501s 8s/step - loss: 1.4895 - accuracy: 0.3500 - val_loss: 1.4873 - val_accuracy: 0.3750\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 493s 8s/step - loss: 1.4365 - accuracy: 0.3758 - val_loss: 1.4189 - val_accuracy: 0.4000\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.4481 - accuracy: 0.3750 - val_loss: 1.4263 - val_accuracy: 0.4450\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.4417 - accuracy: 0.3802 - val_loss: 1.4105 - val_accuracy: 0.3950\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 493s 8s/step - loss: 1.4544 - accuracy: 0.3742 - val_loss: 1.4172 - val_accuracy: 0.3950\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.4335 - accuracy: 0.3844 - val_loss: 1.4275 - val_accuracy: 0.3800\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.3883 - accuracy: 0.4193 - val_loss: 1.4408 - val_accuracy: 0.3750\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 494s 8s/step - loss: 1.3992 - accuracy: 0.4107 - val_loss: 1.4782 - val_accuracy: 0.3550\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.3849 - accuracy: 0.4182 - val_loss: 1.4169 - val_accuracy: 0.4250\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.4043 - accuracy: 0.4036 - val_loss: 1.4403 - val_accuracy: 0.3650\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.3812 - accuracy: 0.4125 - val_loss: 1.4371 - val_accuracy: 0.4100\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 492s 8s/step - loss: 1.3820 - accuracy: 0.4223 - val_loss: 1.4300 - val_accuracy: 0.4200\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 499s 8s/step - loss: 1.3978 - accuracy: 0.4021 - val_loss: 1.4420 - val_accuracy: 0.4300\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 500s 8s/step - loss: 1.3685 - accuracy: 0.4219 - val_loss: 1.4232 - val_accuracy: 0.4450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e63a00b4b20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = Selects,y = labels_one_hot_train,batch_size=32,\n",
    "          epochs=50,  steps_per_epoch=60,\n",
    "         validation_data=(Selects_val, labels_one_hot_val) , callbacks=[EarlyStopping])# 50 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3595c864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:01:44.723702Z",
     "iopub.status.busy": "2023-11-25T15:01:44.723056Z",
     "iopub.status.idle": "2023-11-25T15:01:44.727380Z",
     "shell.execute_reply": "2023-11-25T15:01:44.726494Z"
    },
    "papermill": {
     "duration": 0.233099,
     "end_time": "2023-11-25T15:01:44.729398",
     "exception": false,
     "start_time": "2023-11-25T15:01:44.496299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save('19_epoch_13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc83365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:01:45.174303Z",
     "iopub.status.busy": "2023-11-25T15:01:45.173944Z",
     "iopub.status.idle": "2023-11-25T15:01:45.178245Z",
     "shell.execute_reply": "2023-11-25T15:01:45.177335Z"
    },
    "papermill": {
     "duration": 0.229411,
     "end_time": "2023-11-25T15:01:45.180172",
     "exception": false,
     "start_time": "2023-11-25T15:01:44.950761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_predict = model.predict(Selects)\n",
    "# top_three_indices = (-y_predict).argsort(axis = 1)[:, :3].tolist()\n",
    "# top_max = np.argmax(y_predict,axis = -1)\n",
    "# report = classification_report(labels_one_hot, top_max)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b58d186e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:01:45.628758Z",
     "iopub.status.busy": "2023-11-25T15:01:45.628376Z",
     "iopub.status.idle": "2023-11-25T15:01:45.632559Z",
     "shell.execute_reply": "2023-11-25T15:01:45.631653Z"
    },
    "papermill": {
     "duration": 0.229997,
     "end_time": "2023-11-25T15:01:45.634361",
     "exception": false,
     "start_time": "2023-11-25T15:01:45.404364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in range(len(labels_one_hot)):\n",
    "#     if labels_one_hot[i] in top_three_indices[i]:\n",
    "#         count +=1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0487361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:01:46.076013Z",
     "iopub.status.busy": "2023-11-25T15:01:46.075361Z",
     "iopub.status.idle": "2023-11-25T15:02:51.600091Z",
     "shell.execute_reply": "2023-11-25T15:02:51.598809Z"
    },
    "papermill": {
     "duration": 65.747581,
     "end_time": "2023-11-25T15:02:51.602122",
     "exception": false,
     "start_time": "2023-11-25T15:01:45.854541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 65s 7s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.30      0.38        37\n",
      "           1       0.31      0.35      0.33        48\n",
      "           2       0.41      0.45      0.43        44\n",
      "           3       0.43      0.26      0.33        38\n",
      "           4       0.40      0.64      0.49        33\n",
      "\n",
      "    accuracy                           0.40       200\n",
      "   macro avg       0.42      0.40      0.39       200\n",
      "weighted avg       0.41      0.40      0.39       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(Selects_val)\n",
    "top_three_indices = (-y_predict).argsort(axis = 1)[:, :3].tolist()\n",
    "top_max = np.argmax(y_predict,axis = -1)\n",
    "report = classification_report(labels_one, top_max)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a965809c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:02:52.050299Z",
     "iopub.status.busy": "2023-11-25T15:02:52.049443Z",
     "iopub.status.idle": "2023-11-25T15:02:52.055585Z",
     "shell.execute_reply": "2023-11-25T15:02:52.054275Z"
    },
    "papermill": {
     "duration": 0.230527,
     "end_time": "2023-11-25T15:02:52.057486",
     "exception": false,
     "start_time": "2023-11-25T15:02:51.826959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(labels_one)):\n",
    "    if labels_one[i] in top_three_indices[i]:\n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11971440",
   "metadata": {
    "papermill": {
     "duration": 0.220683,
     "end_time": "2023-11-25T15:02:52.499295",
     "exception": false,
     "start_time": "2023-11-25T15:02:52.278612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DATA TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb88b2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:02:52.952058Z",
     "iopub.status.busy": "2023-11-25T15:02:52.951191Z",
     "iopub.status.idle": "2023-11-25T15:02:52.970642Z",
     "shell.execute_reply": "2023-11-25T15:02:52.969848Z"
    },
    "papermill": {
     "duration": 0.244782,
     "end_time": "2023-11-25T15:02:52.972558",
     "exception": false,
     "start_time": "2023-11-25T15:02:52.727776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_test = ['/kaggle/input/kaggle-llm-science-exam/test.csv']\n",
    "df_scoring = pd.read_csv(path_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "943e6b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:02:53.418208Z",
     "iopub.status.busy": "2023-11-25T15:02:53.417366Z",
     "iopub.status.idle": "2023-11-25T15:03:05.597213Z",
     "shell.execute_reply": "2023-11-25T15:03:05.596229Z"
    },
    "papermill": {
     "duration": 12.407596,
     "end_time": "2023-11-25T15:03:05.602087",
     "exception": false,
     "start_time": "2023-11-25T15:02:53.194491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt embedding, t=0.0s\n",
      "Loading faiss index, t=4.2s\n",
      "Starting text search, t=7.1s\n",
      "Starting context extraction, t=9.9s\n",
      "Context added, t=12.2s\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "start = time()\n",
    "print(f\"Starting prompt embedding, t={time() - start :.1f}s\")\n",
    "\n",
    "# Get embeddings of prompts\n",
    "f = lambda row : \" \".join([str(row[\"prompt\"]), str(row[\"A\"]), str(row[\"B\"]), str(row[\"C\"]), str(row[\"D\"]), str(row[\"E\"])])\n",
    "inputs = df_scoring.apply(f, axis=1).values # better results than prompt only\n",
    "prompt_embeddings = model_faiss.encode(inputs, show_progress_bar=False)\n",
    "\n",
    "# Search closest sentences in the wikipedia index \n",
    "print(f\"Loading faiss index, t={time() - start :.1f}s\")\n",
    "faiss_index = faiss.read_index(MODEL_PATH + '/faiss.index')\n",
    "# faiss_index = faiss.index_cpu_to_all_gpus(faiss_index) # causes OOM, and not that long on CPU\n",
    "\n",
    "print(f\"Starting text search, t={time() - start :.1f}s\")\n",
    "search_index = faiss_index.search(np.float32(prompt_embeddings), NUM_TITLES)[1]\n",
    "\n",
    "print(f\"Starting context extraction, t={time() - start :.1f}s\")\n",
    "dataset = load_from_disk(\"/kaggle/input/all-paraphs-parsed-expanded\")\n",
    "for i in range(len(df_scoring)):\n",
    "    df_scoring.loc[i, \"context\"] = \"-\" + \"\\n-\".join([dataset[int(j)][\"text\"] for j in search_index[i]])\n",
    "\n",
    "# Free memory\n",
    "faiss_index.reset()\n",
    "del faiss_index, prompt_embeddings, dataset\n",
    "clean_memory()\n",
    "print(f\"Context added, t={time() - start :.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "149fddf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:03:06.051771Z",
     "iopub.status.busy": "2023-11-25T15:03:06.051396Z",
     "iopub.status.idle": "2023-11-25T15:03:06.067815Z",
     "shell.execute_reply": "2023-11-25T15:03:06.066921Z"
    },
    "papermill": {
     "duration": 0.24147,
     "end_time": "2023-11-25T15:03:06.069724",
     "exception": false,
     "start_time": "2023-11-25T15:03:05.828254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = read_data(df_scoring,True)\n",
    "X_Prompt = result.get('Prompt') \n",
    "X_Context = result.get('Context') \n",
    "X_A = result.get('Selects').get('A')\n",
    "X_B = result.get('Selects').get('B')\n",
    "X_C = result.get('Selects').get('C')\n",
    "X_D = result.get('Selects').get('D')\n",
    "X_E = result.get('Selects').get('E')\n",
    "Selects = [result.get('Selects')[i] for i in result.get('Selects') ]\n",
    "Selects.insert(0,X_Context)\n",
    "Selects.insert(0,X_Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "875231dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:03:06.516712Z",
     "iopub.status.busy": "2023-11-25T15:03:06.515813Z",
     "iopub.status.idle": "2023-11-25T15:03:52.654312Z",
     "shell.execute_reply": "2023-11-25T15:03:52.653503Z"
    },
    "papermill": {
     "duration": 46.364741,
     "end_time": "2023-11-25T15:03:52.656289",
     "exception": false,
     "start_time": "2023-11-25T15:03:06.291548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 46s 6s/step\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(Selects)\n",
    "top_three_indices = (-y_predict).argsort(axis = 1)[:, :3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f670d25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T15:03:53.108962Z",
     "iopub.status.busy": "2023-11-25T15:03:53.108193Z",
     "iopub.status.idle": "2023-11-25T15:03:53.131154Z",
     "shell.execute_reply": "2023-11-25T15:03:53.130413Z"
    },
    "papermill": {
     "duration": 0.247648,
     "end_time": "2023-11-25T15:03:53.133088",
     "exception": false,
     "start_time": "2023-11-25T15:03:52.885440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mở tệp CSV để ghi\n",
    "df_resutl =  pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\")\n",
    "x = ['A','B','C','D',\"E\"]\n",
    "Label_test = [' '.join([x[int(j)] for j in i]) for i in top_three_indices]\n",
    "\n",
    "for i in range(len(Label_test)):\n",
    "    df_resutl.at[i, 'prediction'] = str(Label_test[i])\n",
    "df_resutl.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5d7c5",
   "metadata": {
    "papermill": {
     "duration": 0.221048,
     "end_time": "2023-11-25T15:03:53.575161",
     "exception": false,
     "start_time": "2023-11-25T15:03:53.354113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6169864,
     "sourceId": 54662,
     "sourceType": "competition"
    },
    {
     "datasetId": 3238926,
     "sourceId": 5632975,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3521629,
     "sourceId": 6146260,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3540289,
     "sourceId": 6175087,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3626780,
     "sourceId": 6315195,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3638263,
     "sourceId": 6363321,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3778974,
     "sourceId": 6536614,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3779689,
     "sourceId": 6537899,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3809212,
     "sourceId": 6602268,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3662908,
     "sourceId": 6359012,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 1910,
     "sourceId": 2644,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 2180,
     "sourceId": 2938,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20425.996184,
   "end_time": "2023-11-25T15:03:57.501635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-25T09:23:31.505451",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
