{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/noor/anaconda3/lib/python3.11/site-packages (1.3.3)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Users/noor/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/noor/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/noor/anaconda3/lib/python3.11/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/noor/anaconda3/lib/python3.11/site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: tqdm>4 in /Users/noor/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/noor/anaconda3/lib/python3.11/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/noor/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/noor/anaconda3/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /Users/noor/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /Users/noor/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/noor/anaconda3/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train.csv\n",
    "# for each row, concatenate columns 'prompt' to 'E' and add the text \n",
    "# save it to a new file\n",
    "import csv \n",
    "\n",
    "with open('./train_context.csv', 'r') as csv_file:\n",
    "    # Create a CSV reader\n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    # Read the header\n",
    "    header = next(reader)\n",
    "    \n",
    "    # Find the indices for columns B to G\n",
    "    b_index, g_index = header.index('prompt'), header.index('E')\n",
    "\n",
    "    # Read all rows into a list\n",
    "    rows = [row for row in reader]\n",
    "\n",
    "# Process the rows\n",
    "appended_rows = []\n",
    "ids = []\n",
    "labels = []\n",
    "for row in rows:\n",
    "    # Concatenate cells B to G with a preceding A, B, C, D, or E \n",
    "    concat_text = 'A. ' + row[b_index+1] + '\\n B. ' + row[b_index+2] + '\\n C. ' + row[b_index+3] + '\\n D. ' + row[b_index+4] + '\\n E. ' + row[b_index+5]\n",
    "    ids.append(row[0])\n",
    "    labels.append(row[6])\n",
    "    text = f\"Answer the following question with A, B, C, D, or E. You can use the context provided. Question: {row[b_index]}\\n Context: {row[b_index+7]}\\n {concat_text} \"\n",
    "    appended_rows.append(text)\n",
    "\n",
    "# Write the result to the output CSV file\n",
    "with open('apiGPT_context.csv', 'w', newline='') as csv_file:\n",
    "    # Create a CSV writer\n",
    "    writer = csv.writer(csv_file)\n",
    "    # put ids and appended rows into a list\n",
    "    prompts = [[i, j] for i, j in zip(ids, appended_rows)]\n",
    "    # Write the header  with the ids and the appended rows to the output file\n",
    "    writer.writerow(['id', 'text'])\n",
    "    writer.writerows(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key='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',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the api on each prompt and save the result to a new file\n",
    "answers = []\n",
    "for prompt in prompts:\n",
    "    answer =client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt= prompt[1], \n",
    "    )\n",
    "    try:\n",
    "        if answer.choices[0].text[2] in ['A', 'B', 'C', 'D', 'E']:\n",
    "            answers.append(answer.choices[0].text[2])\n",
    "        else:\n",
    "            answers.append(answer.choices[0].text)\n",
    "    except:\n",
    "        answers.append(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the answers to the existing apiGPT_context.csv with a new column called 'predicted'\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'apiGPT_context.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df['predicted'] = answers\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# go to the csv and manually fix the predictions that need cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'apiGPT_context.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n",
      "A E\n",
      "A nan\n",
      "C A\n",
      "D A\n",
      "B \n",
      "B\n",
      "A A\n",
      "D B\n",
      "C C\n",
      "A \n",
      "A\n",
      "E E\n",
      "A A\n",
      "C C\n",
      "D  D\n",
      "B  B\n",
      "B B\n",
      "E E\n",
      "E nan\n",
      "A A\n",
      "E nan\n",
      "D \n",
      "D\n",
      "D D\n",
      "C E\n",
      "C C\n",
      "E E\n",
      "E E\n",
      "A A\n",
      "D D\n",
      "E B\n",
      "C C\n",
      "B B\n",
      "E E\n",
      "E nan\n",
      "D D\n",
      "C C\n",
      "B B\n",
      "E D\n",
      "A A\n",
      "E E\n",
      "E A\n",
      "E nan\n",
      "C C\n",
      "B B\n",
      "C C\n",
      "A A\n",
      "A nan\n",
      "B B\n",
      "C C\n",
      "D  D\n",
      "B B\n",
      "B B\n",
      "E E\n",
      "C C\n",
      "A A\n",
      "B B\n",
      "B  B\n",
      "C C\n",
      "C C\n",
      "D D\n",
      "A A\n",
      "B  B\n",
      "B B\n",
      "C C\n",
      "C C\n",
      "A A\n",
      "E D\n",
      "C C\n",
      "E nan\n",
      "C \n",
      "A\n",
      "D \n",
      "D\n",
      "C C\n",
      "A D\n",
      "D D\n",
      "B B\n",
      "D D\n",
      "B B\n",
      "D D\n",
      "B B\n",
      "C C\n",
      "E E\n",
      "C C\n",
      "A D\n",
      "B B\n",
      "A A\n",
      "C  C\n",
      "D D\n",
      "D D\n",
      "B B\n",
      "E E\n",
      "D E\n",
      "B B\n",
      "B B\n",
      "B B\n",
      "E E\n",
      "E E\n",
      "C C\n",
      "C E\n",
      "D D\n",
      "D D\n",
      "D  D\n",
      "D D\n",
      "B A\n",
      "C C\n",
      "B C\n",
      "C C\n",
      "D D\n",
      "A A\n",
      "D D\n",
      "A A\n",
      "D D\n",
      "C C\n",
      "D B\n",
      "A D\n",
      "B B\n",
      "D D\n",
      "E nan\n",
      "B B\n",
      "C C\n",
      "D D\n",
      "A A\n",
      "A A\n",
      "C D\n",
      "B B\n",
      "A B\n",
      "B B\n",
      "D D\n",
      "B B\n",
      "C nan\n",
      "E  E\n",
      "E E\n",
      "A A\n",
      "C C\n",
      "E E\n",
      "B B\n",
      "C C\n",
      "E E\n",
      "E E\n",
      "D C\n",
      "A A\n",
      "A A\n",
      "C C\n",
      "E E\n",
      "B B\n",
      "A A\n",
      "C C\n",
      "B B\n",
      "B B\n",
      "C A\n",
      "B B\n",
      "B B\n",
      "B B\n",
      "D D\n",
      "A A\n",
      "A A\n",
      "B B\n",
      "E E\n",
      "D D\n",
      "C C\n",
      "A A\n",
      "A A\n",
      "A A\n",
      "E E\n",
      "B A\n",
      "B B\n",
      "C C\n",
      "D nan\n",
      "B B\n",
      "D D\n",
      "E E\n",
      "A A\n",
      "B E\n",
      "E  E\n",
      "B B\n",
      "C D\n",
      "B A\n",
      "E E\n",
      "D E\n",
      "D C\n",
      "C A\n",
      "C C\n",
      "B B\n",
      "A A\n",
      "A A\n",
      "C C\n",
      "A B\n",
      "A A\n",
      "C nan\n",
      "A B\n",
      "D D\n",
      "B B\n",
      "E D\n",
      "C C\n",
      "B B\n",
      "B B\n",
      "D D\n",
      "C C\n",
      "B B\n",
      "B B\n",
      "D D\n",
      "C A\n"
     ]
    }
   ],
   "source": [
    "#Â compare the answers to the correct answers and calculate the accuracy\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for label, answer in zip(labels, df['predicted']):\n",
    "    try:\n",
    "        if label == answer.strip():\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    except:\n",
    "        incorrect += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
